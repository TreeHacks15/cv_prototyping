{
 "metadata": {
  "name": "",
  "signature": "sha256:3b92fe7488c08aaf119a4ce443b960f5e67deae45b192bb7c2055cb26a11d8be"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# CubeML: Machine Learning"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "sys.path.insert(0, '../')\n",
      "import numpy as np\n",
      "import scipy as sp\n",
      "import cv2\n",
      "import matplotlib.pyplot as plt\n",
      "%pylab inline\n",
      "\n",
      "from cv_prototyping import *\n",
      "from cv_prototyping.rubiks import Cube\n",
      "from cv_prototyping.ml import get_frames_labels_paths"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING: pylab import has clobbered these variables: ['f', 'contour']\n",
        "`%matplotlib` prevents importing * from pylab and numpy\n"
       ]
      }
     ],
     "prompt_number": 98
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Get frame, labels "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "paths = get_frames_labels_paths()\n",
      "frame_paths = [p[0] for p in paths]\n",
      "label_paths = [p[1] for p in paths]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 99
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Get cropped images, labels, contours"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cube = Cube()\n",
      "images = [cv2.imread(p) for p in frame_paths]\n",
      "cropped_images = [cube.get_cropped(img) for img in images]\n",
      "labels = [np.load(p) for p in label_paths]\n",
      "contours = [cube.get_contours(img) for img in images]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 100
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Featurize"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def featurize(img, contour):\n",
      "    \"\"\"\n",
      "    image, contour -> label \n",
      "    \"\"\"\n",
      "    features = []\n",
      "    #=====[ Step 1: fit an ellipse]=====\n",
      "    ellipse = cv2.fitEllipse(contour)\n",
      "    a, b, c = ellipse\n",
      "    features.append(a[0])\n",
      "    features.append(a[1])\n",
      "    features.append(b[0])\n",
      "    features.append(b[1])\n",
      "    features.append(c)\n",
      "\n",
      "    #=====[ Step 2: mask image ]=====\n",
      "    mask = np.zeros((img.shape[0], img.shape[1]))\n",
      "    cv2.ellipse(mask, ellipse, color=255, thickness=-1)\n",
      "    mask = mask.astype(bool)\n",
      "    masked = img[mask]\n",
      "\n",
      "    #     cv2.ellipse(img, ellipse, color=(255, 0, 0), thickness=2)\n",
      "#     cv2.drawContours(img, [contour], -1, (0, 255, 0), 3)\n",
      "#     plt.imshow(img)\n",
      "    \n",
      "    #=====[ Step 3: histogram ]=====\n",
      "    hist0, bins = np.histogram(masked[:,0],4,[0,256])\n",
      "    hist1, bins = np.histogram(masked[:,1],4,[0,256])\n",
      "    hist2, bins = np.histogram(masked[:,2],4,[0,256])\n",
      "    hist0 = hist0.astype(np.float64)\n",
      "    hist1 = hist1.astype(np.float64)\n",
      "    hist2 = hist2.astype(np.float64)\n",
      "    hist0 /= hist0.sum()\n",
      "    hist1 /= hist1.sum()\n",
      "    hist2 /= hist2.sum()\n",
      "    features += [np.nanstd(hist0), np.nanmax(hist0), np.nansum(hist0 == 0)]\n",
      "#     features += list(hist0)\n",
      "    features += [np.nanstd(hist1), np.nanmax(hist1), np.nansum(hist1 == 0)]\n",
      "#     features += list(hist1)\n",
      "    features += [np.nanstd(hist2), np.nanmax(hist2), np.nansum(hist2 == 0)]\n",
      "#     print sum(hist0 == 0)\n",
      "#     features += list(hist2)\n",
      "#     print features\n",
      "#     features += list(hist2)\n",
      "    features = np.nan_to_num(features)\n",
      "    return features\n",
      "    #     return features\n",
      "\n",
      "#     return features\n",
      "# img = cropped_images[1].copy()\n",
      "# contour = contours[1][0]\n",
      "# featurize(img, contour)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 141
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Featurize"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = []\n",
      "y = []\n",
      "for i, image in enumerate(cropped_images):\n",
      "    for j, contour in enumerate(contours[i]):\n",
      "        l = labels[i][j]\n",
      "        f = featurize(image, contour)\n",
      "        X.append(f)\n",
      "        y.append(l)\n",
      "X = np.array(X)\n",
      "y = np.array(y)\n",
      "print X[:10, :10]\n",
      "print X.shape\n",
      "print y.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[  1.60348175e+02   1.31121368e+02   1.52254953e+01   3.93009834e+01\n",
        "    3.61566620e+01   2.33768161e-01   4.96138996e-01   0.00000000e+00\n",
        "    3.98489689e-01   9.40154440e-01]\n",
        " [  1.30636398e+02   1.12135071e+02   1.37405586e+01   4.22901268e+01\n",
        "    3.57485657e+01   3.85045901e-01   9.16666667e-01   0.00000000e+00\n",
        "    2.43106166e-01   4.98015873e-01]\n",
        " [ -1.25986649e+02   5.76113892e+02   2.09907364e+02   7.54403564e+02\n",
        "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
        "    0.00000000e+00   0.00000000e+00]\n",
        " [  1.51760452e+02   2.57554932e+02   3.36549721e+01   4.03654594e+01\n",
        "    8.45747833e+01   1.78119078e-01   4.21665175e-01   1.00000000e+00\n",
        "    1.60738038e-01   4.21665175e-01]\n",
        " [  1.72880997e+02   2.47840195e+02   1.44335432e+01   6.42885895e+01\n",
        "    1.17654198e+02   3.20250414e-01   7.97966963e-01   0.00000000e+00\n",
        "    3.18103093e-01   7.92884371e-01]\n",
        " [  1.75187561e+02   2.17779053e+02   1.00869751e+01   4.05091324e+01\n",
        "    2.90921059e+01   2.59952036e-01   6.19178082e-01   1.00000000e+00\n",
        "    2.35977543e-01   6.19178082e-01]\n",
        " [  1.42489990e+02   1.90010849e+02   3.18699455e+01   3.79862213e+01\n",
        "    4.11731453e+01   2.63742347e-01   6.40159046e-01   0.00000000e+00\n",
        "    4.22118031e-01   9.81113320e-01]\n",
        " [  1.58405655e+02   1.66656754e+02   9.90704823e+00   3.26956558e+01\n",
        "    1.11778725e+02   3.31667537e-01   8.19727891e-01   0.00000000e+00\n",
        "    3.99775638e-01   9.42176871e-01]\n",
        " [  1.11952591e+02   1.74069946e+02   2.90501938e+01   3.60475311e+01\n",
        "    4.50428658e+01   2.70033229e-01   6.53579677e-01   0.00000000e+00\n",
        "    4.27679472e-01   9.90762125e-01]\n",
        " [  8.75473175e+01   1.56629913e+02   2.10106125e+01   2.66695576e+01\n",
        "    1.91915226e+01   2.50164627e-01   5.99156118e-01   0.00000000e+00\n",
        "    3.39329777e-01   8.33333333e-01]]\n",
        "(201, 14)\n",
        "(201,)\n"
       ]
      }
     ],
     "prompt_number": 142
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## ML"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sklearn\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.svm import SVC\n",
      "from sklearn import cross_validation\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.decomposition import PCA, KernelPCA\n",
      "\n",
      "pipeline = Pipeline([\n",
      "#                         ('PCA', KernelPCA(n_components=10, kernel='rbf')),\n",
      "                        ('RandomForest', RandomForestClassifier())\n",
      "])\n",
      "# pipeline.fit(X,y)\n",
      "# yhat = pipeline.predict(X)\n",
      "print len(y)\n",
      "print sum(yhat == y)\n",
      "cross_validation.cross_val_score(pipeline, X, y, cv=4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "201\n",
        "199\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 163,
       "text": [
        "array([ 0.88235294,  0.94      ,  0.92      ,  0.88      ])"
       ]
      }
     ],
     "prompt_number": 163
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 150
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}